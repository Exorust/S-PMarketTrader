{
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 73231,
          "databundleVersionId": 8133715,
          "sourceType": "competition"
        },
        {
          "sourceId": 7369493,
          "sourceType": "datasetVersion",
          "datasetId": 4281572
        },
        {
          "sourceId": 8023365,
          "sourceType": "datasetVersion",
          "datasetId": 4728129
        },
        {
          "sourceId": 8099055,
          "sourceType": "datasetVersion",
          "datasetId": 4782541
        },
        {
          "sourceId": 8105719,
          "sourceType": "datasetVersion",
          "datasetId": 4739401
        },
        {
          "sourceId": 171785036,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 724.728315,
      "end_time": "2024-02-29T09:37:08.760349",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-02-29T09:25:04.032034",
      "version": "2.5.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {
          "21267b653022419eb6fc3f47aa4db8ed": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "HTMLModel",
            "state": {
              "_dom_classes": [],
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "HTMLModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/controls",
              "_view_module_version": "1.5.0",
              "_view_name": "HTMLView",
              "description": "",
              "description_tooltip": null,
              "layout": "IPY_MODEL_926e7ccdad6440be85c76931860b744c",
              "placeholder": "​",
              "style": "IPY_MODEL_feef8334edb24f6da22e8bb1d8d80c67",
              "value": "Loading checkpoint shards: 100%"
            }
          },
          "2144e851698b4707ad1c7fc29fe21b03": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "model_name": "LayoutModel",
            "state": {
              "_model_module": "@jupyter-widgets/base",
              "_model_module_version": "1.2.0",
              "_model_name": "LayoutModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "LayoutView",
              "align_content": null,
              "align_items": null,
              "align_self": null,
              "border": null,
              "bottom": null,
              "display": null,
              "flex": null,
              "flex_flow": null,
              "grid_area": null,
              "grid_auto_columns": null,
              "grid_auto_flow": null,
              "grid_auto_rows": null,
              "grid_column": null,
              "grid_gap": null,
              "grid_row": null,
              "grid_template_areas": null,
              "grid_template_columns": null,
              "grid_template_rows": null,
              "height": null,
              "justify_content": null,
              "justify_items": null,
              "left": null,
              "margin": null,
              "max_height": null,
              "max_width": null,
              "min_height": null,
              "min_width": null,
              "object_fit": null,
              "object_position": null,
              "order": null,
              "overflow": null,
              "overflow_x": null,
              "overflow_y": null,
              "padding": null,
              "right": null,
              "top": null,
              "visibility": null,
              "width": null
            }
          },
          "3963993becfa487c9ff725f211915e67": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "HTMLModel",
            "state": {
              "_dom_classes": [],
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "HTMLModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/controls",
              "_view_module_version": "1.5.0",
              "_view_name": "HTMLView",
              "description": "",
              "description_tooltip": null,
              "layout": "IPY_MODEL_f7a725e1b0cc4ad78a62beab5f663065",
              "placeholder": "​",
              "style": "IPY_MODEL_fdb32baaed7145d8a8024b615ef242ca",
              "value": " 19/19 [10:48&lt;00:00, 33.24s/it]"
            }
          },
          "5882b6e860be4a0db012a64fc0704a3f": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "HBoxModel",
            "state": {
              "_dom_classes": [],
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "HBoxModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/controls",
              "_view_module_version": "1.5.0",
              "_view_name": "HBoxView",
              "box_style": "",
              "children": [
                "IPY_MODEL_21267b653022419eb6fc3f47aa4db8ed",
                "IPY_MODEL_d91eb83d016a4381828192a98f798f9b",
                "IPY_MODEL_3963993becfa487c9ff725f211915e67"
              ],
              "layout": "IPY_MODEL_6a892a5561f742bb9db9f13859c18e90"
            }
          },
          "6a892a5561f742bb9db9f13859c18e90": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "model_name": "LayoutModel",
            "state": {
              "_model_module": "@jupyter-widgets/base",
              "_model_module_version": "1.2.0",
              "_model_name": "LayoutModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "LayoutView",
              "align_content": null,
              "align_items": null,
              "align_self": null,
              "border": null,
              "bottom": null,
              "display": null,
              "flex": null,
              "flex_flow": null,
              "grid_area": null,
              "grid_auto_columns": null,
              "grid_auto_flow": null,
              "grid_auto_rows": null,
              "grid_column": null,
              "grid_gap": null,
              "grid_row": null,
              "grid_template_areas": null,
              "grid_template_columns": null,
              "grid_template_rows": null,
              "height": null,
              "justify_content": null,
              "justify_items": null,
              "left": null,
              "margin": null,
              "max_height": null,
              "max_width": null,
              "min_height": null,
              "min_width": null,
              "object_fit": null,
              "object_position": null,
              "order": null,
              "overflow": null,
              "overflow_x": null,
              "overflow_y": null,
              "padding": null,
              "right": null,
              "top": null,
              "visibility": null,
              "width": null
            }
          },
          "926e7ccdad6440be85c76931860b744c": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "model_name": "LayoutModel",
            "state": {
              "_model_module": "@jupyter-widgets/base",
              "_model_module_version": "1.2.0",
              "_model_name": "LayoutModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "LayoutView",
              "align_content": null,
              "align_items": null,
              "align_self": null,
              "border": null,
              "bottom": null,
              "display": null,
              "flex": null,
              "flex_flow": null,
              "grid_area": null,
              "grid_auto_columns": null,
              "grid_auto_flow": null,
              "grid_auto_rows": null,
              "grid_column": null,
              "grid_gap": null,
              "grid_row": null,
              "grid_template_areas": null,
              "grid_template_columns": null,
              "grid_template_rows": null,
              "height": null,
              "justify_content": null,
              "justify_items": null,
              "left": null,
              "margin": null,
              "max_height": null,
              "max_width": null,
              "min_height": null,
              "min_width": null,
              "object_fit": null,
              "object_position": null,
              "order": null,
              "overflow": null,
              "overflow_x": null,
              "overflow_y": null,
              "padding": null,
              "right": null,
              "top": null,
              "visibility": null,
              "width": null
            }
          },
          "d91eb83d016a4381828192a98f798f9b": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "FloatProgressModel",
            "state": {
              "_dom_classes": [],
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "FloatProgressModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/controls",
              "_view_module_version": "1.5.0",
              "_view_name": "ProgressView",
              "bar_style": "success",
              "description": "",
              "description_tooltip": null,
              "layout": "IPY_MODEL_2144e851698b4707ad1c7fc29fe21b03",
              "max": 19,
              "min": 0,
              "orientation": "horizontal",
              "style": "IPY_MODEL_e0693b32889c42b18b9a3844e045d048",
              "value": 19
            }
          },
          "e0693b32889c42b18b9a3844e045d048": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "ProgressStyleModel",
            "state": {
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "ProgressStyleModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "StyleView",
              "bar_color": null,
              "description_width": ""
            }
          },
          "f7a725e1b0cc4ad78a62beab5f663065": {
            "model_module": "@jupyter-widgets/base",
            "model_module_version": "1.2.0",
            "model_name": "LayoutModel",
            "state": {
              "_model_module": "@jupyter-widgets/base",
              "_model_module_version": "1.2.0",
              "_model_name": "LayoutModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "LayoutView",
              "align_content": null,
              "align_items": null,
              "align_self": null,
              "border": null,
              "bottom": null,
              "display": null,
              "flex": null,
              "flex_flow": null,
              "grid_area": null,
              "grid_auto_columns": null,
              "grid_auto_flow": null,
              "grid_auto_rows": null,
              "grid_column": null,
              "grid_gap": null,
              "grid_row": null,
              "grid_template_areas": null,
              "grid_template_columns": null,
              "grid_template_rows": null,
              "height": null,
              "justify_content": null,
              "justify_items": null,
              "left": null,
              "margin": null,
              "max_height": null,
              "max_width": null,
              "min_height": null,
              "min_width": null,
              "object_fit": null,
              "object_position": null,
              "order": null,
              "overflow": null,
              "overflow_x": null,
              "overflow_y": null,
              "padding": null,
              "right": null,
              "top": null,
              "visibility": null,
              "width": null
            }
          },
          "fdb32baaed7145d8a8024b615ef242ca": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "DescriptionStyleModel",
            "state": {
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "DescriptionStyleModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "StyleView",
              "description_width": ""
            }
          },
          "feef8334edb24f6da22e8bb1d8d80c67": {
            "model_module": "@jupyter-widgets/controls",
            "model_module_version": "1.5.0",
            "model_name": "DescriptionStyleModel",
            "state": {
              "_model_module": "@jupyter-widgets/controls",
              "_model_module_version": "1.5.0",
              "_model_name": "DescriptionStyleModel",
              "_view_count": null,
              "_view_module": "@jupyter-widgets/base",
              "_view_module_version": "1.2.0",
              "_view_name": "StyleView",
              "description_width": ""
            }
          }
        },
        "version_major": 2,
        "version_minor": 0
      }
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Thank you to https://www.kaggle.com/code/quan0095/more-diversity-in-output-improve-score\n# Rho-1 model [Rho-1: Not All Tokens Are What You Need](https://github.com/microsoft/rho?tab=readme-ov-file)\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# credits:\n# https://www.kaggle.com/code/olyatsimboy/aimo-openmath-mistral-baseline\n# https://www.kaggle.com/code/aatiffraz/prompt-prediction-w-mixtral-mistral7b-gemma-llama\n# https://www.kaggle.com/code/thedrcat/aimo-mixtral-baseline",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:41:31.448688Z",
          "iopub.execute_input": "2024-04-24T23:41:31.449601Z",
          "iopub.status.idle": "2024-04-24T23:41:31.454547Z",
          "shell.execute_reply.started": "2024-04-24T23:41:31.449567Z",
          "shell.execute_reply": "2024-04-24T23:41:31.453546Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Zero-shot MMOS-DeepSeekMath-7B with self-consistency and generated code reasoning evaluation\n\nSelf-consistency is a modification of the standard greedy decoding in reasoning pipelines via sampling several diverse answers followed by aggregation, e.g., most common answer ([SC-CoT paper](https://arxiv.org/pdf/2203.11171.pdf)).\n\nIn this kernel, we will consider MMOS-DeepSeekMath-7B RL-tuned backbone; in my experiments, this model produces more consistent code reasoning and the code block execution will allow us to decrease arithmetic hallucinations.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "!pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq\n",
      "metadata": {
        "papermill": {
          "duration": 18.075198,
          "end_time": "2024-02-29T09:25:25.295954",
          "exception": false,
          "start_time": "2024-02-29T09:25:07.220756",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-24T23:41:31.456380Z",
          "iopub.execute_input": "2024-04-24T23:41:31.457226Z",
          "iopub.status.idle": "2024-04-24T23:42:08.492115Z",
          "shell.execute_reply.started": "2024-04-24T23:41:31.457199Z",
          "shell.execute_reply": "2024-04-24T23:42:08.490861Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import torch\nfrom transformers import (\n    AutoModelForCausalLM, \n    AutoTokenizer, \n    BitsAndBytesConfig, \n    AutoConfig,\n    set_seed\n)\n\nset_seed(42)\n\nMODEL_PATH = \"/kaggle/input/microsoftrho-math-7b-interpreter-v0-1/rho-math-7b-interpreter-v0.1\"\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n)\n\nconfig = AutoConfig.from_pretrained(MODEL_PATH)\nconfig.gradient_checkpointing = True\n\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_PATH,\n    device_map=\"auto\",\n    torch_dtype=\"auto\",\n    trust_remote_code=True,\n#     quantization_config=quantization_config,\n    config=config\n)",
      "metadata": {
        "papermill": {
          "duration": 664.688061,
          "end_time": "2024-02-29T09:36:29.988515",
          "exception": false,
          "start_time": "2024-02-29T09:25:25.300454",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-24T23:42:08.494438Z",
          "iopub.execute_input": "2024-04-24T23:42:08.494770Z",
          "iopub.status.idle": "2024-04-24T23:45:12.154826Z",
          "shell.execute_reply.started": "2024-04-24T23:42:08.494740Z",
          "shell.execute_reply": "2024-04-24T23:45:12.153971Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "model.dtype",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:45:12.156269Z",
          "iopub.execute_input": "2024-04-24T23:45:12.157024Z",
          "iopub.status.idle": "2024-04-24T23:45:12.164474Z",
          "shell.execute_reply.started": "2024-04-24T23:45:12.156986Z",
          "shell.execute_reply": "2024-04-24T23:45:12.163494Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom tqdm import tqdm\nPRIVATE = True\n\ndf = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/test.csv')\ndf.head()",
      "metadata": {
        "papermill": {
          "duration": 1.224774,
          "end_time": "2024-02-29T09:36:31.21757",
          "exception": false,
          "start_time": "2024-02-29T09:36:29.992796",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-24T23:45:12.167423Z",
          "iopub.execute_input": "2024-04-24T23:45:12.167833Z",
          "iopub.status.idle": "2024-04-24T23:45:12.195212Z",
          "shell.execute_reply.started": "2024-04-24T23:45:12.167800Z",
          "shell.execute_reply": "2024-04-24T23:45:12.194269Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "if len(df) < 5:\n    df = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/train.csv')\n    PRIVATE = False\ndf.head()",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:45:12.196476Z",
          "iopub.execute_input": "2024-04-24T23:45:12.196871Z",
          "iopub.status.idle": "2024-04-24T23:45:12.213609Z",
          "shell.execute_reply.started": "2024-04-24T23:45:12.196834Z",
          "shell.execute_reply": "2024-04-24T23:45:12.212700Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import gc\ndevice = 'cuda'",
      "metadata": {
        "papermill": {
          "duration": 0.022605,
          "end_time": "2024-02-29T09:36:31.265878",
          "exception": false,
          "start_time": "2024-02-29T09:36:31.243273",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-24T23:45:12.214528Z",
          "iopub.execute_input": "2024-04-24T23:45:12.214771Z",
          "iopub.status.idle": "2024-04-24T23:45:12.218964Z",
          "shell.execute_reply.started": "2024-04-24T23:45:12.214750Z",
          "shell.execute_reply": "2024-04-24T23:45:12.217957Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def naive_parse(answer):\n    out = []\n    start = False\n    end = False\n    for l in reversed(list(answer)):\n        if l in '0123456789' and not end:\n            start = True\n            out.append(l)\n        else:\n            if start:\n                end = True\n        \n    out = reversed(out)\n    return ''.join(out)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:45:12.220043Z",
          "iopub.execute_input": "2024-04-24T23:45:12.220357Z",
          "iopub.status.idle": "2024-04-24T23:45:12.228323Z",
          "shell.execute_reply.started": "2024-04-24T23:45:12.220332Z",
          "shell.execute_reply": "2024-04-24T23:45:12.227520Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import transformers\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype='auto',\n    device_map=\"cuda\",\n)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:45:12.229301Z",
          "iopub.execute_input": "2024-04-24T23:45:12.229561Z",
          "iopub.status.idle": "2024-04-24T23:45:14.913579Z",
          "shell.execute_reply.started": "2024-04-24T23:45:12.229539Z",
          "shell.execute_reply": "2024-04-24T23:45:14.912562Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(f\"Transformers Version: {transformers.__version__}\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:45:14.914860Z",
          "iopub.execute_input": "2024-04-24T23:45:14.915438Z",
          "iopub.status.idle": "2024-04-24T23:45:14.920329Z",
          "shell.execute_reply.started": "2024-04-24T23:45:14.915402Z",
          "shell.execute_reply": "2024-04-24T23:45:14.919364Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import torch\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:45:14.923443Z",
          "iopub.execute_input": "2024-04-24T23:45:14.923750Z",
          "iopub.status.idle": "2024-04-24T23:45:14.931033Z",
          "shell.execute_reply.started": "2024-04-24T23:45:14.923725Z",
          "shell.execute_reply": "2024-04-24T23:45:14.930169Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import re\nimport sys\nimport subprocess\n\n\ndef process_output(output):\n    result = output\n    \n    try:\n        code = output.split('```')[1][7:]\n\n        with open('code.py', 'w') as fout:\n            fout.write(code)\n\n        batcmd = 'timeout 7 ' + sys.executable + ' code.py'\n        try:\n            shell_output = subprocess.check_output(batcmd, shell=True).decode('utf8')\n            print(shell_output)\n            code_output = round(float(eval(shell_output))) % 1000\n        except:\n            code_output = -1\n\n        print('CODE RESULTS', code_output)\n    \n    except Exception as e:\n        print(e)\n        print('ERROR PARSING')\n        code_output = -1\n    \n    try:\n        result_output = re.findall(r'\\\\boxed\\{(.*)\\}', result)\n\n        print('BOXED', result_output)\n        if not len(result_output):\n            result_output = naive_parse(result)\n        else:\n            result_output = result_output[-1]\n\n        print('BOXED', result_output)\n        if not len(result_output):\n            result_output = -1\n        \n        else:\n            result_output = round(float(eval(result_output))) % 1000\n    \n    except Exception as e:\n        print(e)\n        print('ERROR PARSING')\n        result_output = -1\n    \n    return result_output, code_output",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:45:14.932036Z",
          "iopub.execute_input": "2024-04-24T23:45:14.932364Z",
          "iopub.status.idle": "2024-04-24T23:45:14.947336Z",
          "shell.execute_reply.started": "2024-04-24T23:45:14.932333Z",
          "shell.execute_reply": "2024-04-24T23:45:14.946512Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def toMin(s   ):\n     res = s   \n     if ('hours and' in s ):\n       if ('minutes' in s[s.index('hours and'): ]):  \n         if s.index('minutes',s.index('hours and'))-s.index('hours and') == 13:  \n           res =  s[0:s.index('hours and')-3]+ ' '+ str(int(s[s.index('hours and')-3:s.index('hours and')])*60  + int(s[s.index('hours and')-2+12:s.index('hours and')+12]))+ ' '+ s[s.index('minutes',s.index('hours and')): ] \n         if s.index('minutes',s.index('hours and'))-s.index('hours and') == 12:  \n           res =  s[0:s.index('hours and')-3]+ ' '+ str(int(s[s.index('hours and')-3:s.index('hours and')])*60  + int(s[s.index('hours and')-2+12:s.index('hours and')+12]))+ ' '+ s[s.index('minutes',s.index('hours and')): ] \n     return res \ndef toMin_Many(s   ):\n    s_old = s\n    s_new = toMin(s_old )\n    while 1==1:\n        if s_old == s_new:\n            break\n        else:\n           s_old = s_new\n           s_new = toMin(s_old ) \n    s  = s_new\n    return s",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:45:14.948266Z",
          "iopub.execute_input": "2024-04-24T23:45:14.948571Z",
          "iopub.status.idle": "2024-04-24T23:45:14.959146Z",
          "shell.execute_reply.started": "2024-04-24T23:45:14.948549Z",
          "shell.execute_reply": "2024-04-24T23:45:14.958409Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# Running the model",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import re\nfrom collections import defaultdict\n\ndef tool_instruction(problem):\n    return f\"\"\"Problem: {problem}\n\nChain of Thought:\n\nUnderstanding the Problem: Clearly describe what the problem is asking. This involves identifying key quantities and operations needed to solve the problem.\nDevising a Plan: Determine the steps required to solve the problem. This may involve formulas, identifying patterns, or setting up equations.\nExecuting the Plan: Carry out the steps outlined in the plan. This part should include calculations, iterations, or any logical reasoning required to get to the solution.\nChecking the Work: Verify the solution for correctness and consistency with the problem requirements.\nFormatting the Final Answer: Present the final answer in the required format. According to the instructions given:\nThe answer should be a non-negative number.\nApply modulo 1000 operation to ensure the result is within the correct range.\nPut your final answer within \\\\boxed{{}}\n\"\"\"\n# tool_instruction += '\\nPlease integrate natural language reasoning with programs to solve the problem above, and put your final answer within \\\\boxed{}.'\n# tool_instruction = open(\"/kaggle/input/aimo-cot-prompt/AIMO_prompt.txt\").read()\n\n\nn_repetitions = 5 if PRIVATE else 2\n\ntotal_results = []\ntotal_answers = []\n\nfor i in tqdm(range(len(df))):\n    id_ = df['id'].loc[i]\n    problem = df['problem'].loc[i]\n    problem = toMin_Many(problem   )\n    messages = [\n        {\n            \"role\": \"user\", \n#             \"content\":  tool_instruction + \"Question:\"+ problem\n            \"content\": tool_instruction(problem)\n\n#             \"content\": problem + tool_instruction\n        }\n    ]\n    \n    query_prompt = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False\n    )\n    \n    results = []\n    answers = []\n    \n    for _ in tqdm(range(n_repetitions)):\n        try:\n            raw_output = pipeline(\n                query_prompt, \n                max_new_tokens=2048, \n                do_sample=True, \n                temperature=0.9,\n                return_full_text=False\n            )\n            raw_output = raw_output[0]['generated_text']\n\n            result_output, code_output = process_output(raw_output)\n            print(\"=\"*10)\n            print(\"Q:\" + query_prompt)\n            print(\"R:\" + raw_output)\n            print(\"C:\" + code_output)\n            print()\n            print()\n            print(\"=\"*10)\n#             break\n            torch.cuda.empty_cache()\n            gc.collect()\n\n        except Exception as e:\n            print(e)\n            result_output, code_output = -1, -1\n        \n        results.append(result_output)\n        answers.append(code_output)\n    \n    total_results.append(results)\n    total_answers.append(answers)",
      "metadata": {
        "papermill": {
          "duration": 34.259365,
          "end_time": "2024-02-29T09:37:05.548829",
          "exception": false,
          "start_time": "2024-02-29T09:36:31.289464",
          "status": "completed"
        },
        "tags": [],
        "_kg_hide-output": true,
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-04-25T00:33:41.114238Z",
          "iopub.execute_input": "2024-04-25T00:33:41.115081Z",
          "iopub.status.idle": "2024-04-25T00:46:22.287111Z",
          "shell.execute_reply.started": "2024-04-25T00:33:41.115041Z",
          "shell.execute_reply": "2024-04-25T00:46:22.286234Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom collections import Counter\n\nfinal_answers = []\n\nfor a, b in zip(total_answers, total_results):\n    a = np.array(a)\n    b = np.array(b)\n    a[a < 0] = b[a < 0]\n    \n    pred = Counter(a.tolist()).most_common(2)\n\n    ans = pred[0][0] if not pred[0][0] < 0 else pred[1][0]\n\n    final_answers.append(ans)\n    print(ans)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:57:24.577999Z",
          "iopub.execute_input": "2024-04-24T23:57:24.579028Z",
          "iopub.status.idle": "2024-04-24T23:57:24.587595Z",
          "shell.execute_reply.started": "2024-04-24T23:57:24.578982Z",
          "shell.execute_reply": "2024-04-24T23:57:24.586667Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df['answer'] = final_answers",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:57:24.588779Z",
          "iopub.execute_input": "2024-04-24T23:57:24.589144Z",
          "iopub.status.idle": "2024-04-24T23:57:24.605349Z",
          "shell.execute_reply.started": "2024-04-24T23:57:24.589112Z",
          "shell.execute_reply": "2024-04-24T23:57:24.604560Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:57:24.606498Z",
          "iopub.execute_input": "2024-04-24T23:57:24.607224Z",
          "iopub.status.idle": "2024-04-24T23:57:24.620740Z",
          "shell.execute_reply.started": "2024-04-24T23:57:24.607193Z",
          "shell.execute_reply": "2024-04-24T23:57:24.619795Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df[['id','answer']].to_csv(\"submission.csv\", header=True, index=False)",
      "metadata": {
        "papermill": {
          "duration": 0.021128,
          "end_time": "2024-02-29T09:37:05.574782",
          "exception": false,
          "start_time": "2024-02-29T09:37:05.553654",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-24T23:57:24.621854Z",
          "iopub.execute_input": "2024-04-24T23:57:24.622514Z",
          "iopub.status.idle": "2024-04-24T23:57:24.645189Z",
          "shell.execute_reply.started": "2024-04-24T23:57:24.622483Z",
          "shell.execute_reply": "2024-04-24T23:57:24.644318Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df[['id','answer']].head()",
      "metadata": {
        "papermill": {
          "duration": 0.014339,
          "end_time": "2024-02-29T09:37:05.594605",
          "exception": false,
          "start_time": "2024-02-29T09:37:05.580266",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2024-04-24T23:57:24.646379Z",
          "iopub.execute_input": "2024-04-24T23:57:24.646841Z",
          "iopub.status.idle": "2024-04-24T23:57:24.656495Z",
          "shell.execute_reply.started": "2024-04-24T23:57:24.646816Z",
          "shell.execute_reply": "2024-04-24T23:57:24.655450Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "if not PRIVATE:\n    df = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/train.csv')\n    df['model_answer'] = final_answers\n    df['match'] = df.answer == df.model_answer\n    print(f'{df.match.sum()} matches in {len(df)} examples')",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-24T23:57:24.657726Z",
          "iopub.execute_input": "2024-04-24T23:57:24.658047Z",
          "iopub.status.idle": "2024-04-24T23:57:24.670776Z",
          "shell.execute_reply.started": "2024-04-24T23:57:24.658019Z",
          "shell.execute_reply": "2024-04-24T23:57:24.669792Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}